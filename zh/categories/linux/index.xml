<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Linux - category - *&lt;^_^>*</title><link>https://caijin.dev/zh/categories/linux/</link><description>Linux - category | *&lt;^_^>*</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>xxxx</copyright><lastBuildDate>Sat, 02 May 2020 20:18:42 +0800</lastBuildDate><atom:link href="https://caijin.dev/zh/categories/linux/" rel="self" type="application/rss+xml"/><item><title>kafka简介</title><link>https://caijin.dev/zh/kafka/kafka/</link><pubDate>Sat, 02 May 2020 20:18:42 +0800</pubDate><author>caijin</author><guid>https://caijin.dev/zh/kafka/kafka/</guid><description>Kafka 一、基本概念 kafka cluster：kafka集群，一个集群由多个实例（broker）组成，通过zookeeper进行元数据（brokerID、broker 地址等信息，partition的leader、follower信息等）共享与同步 broker：kafka集群中的一个kafka服务实例，集群内每个broker都有一个不重复的编号，如broker-0、broker-1 producer：消息生产者 topic：消息主题，可以理解为消息分类，为逻辑概念。Kafka的消息就保存在topic，每个broker上都可以创建多个topic。 partition：topic的分区，每个topic可以有多个分区，分区的作用是做负载，提高Kafka的吞吐量。同一个topic在不同分区的数据是不重复的，partition的表现形式就是一个个文件夹，为物理概念。 replication：分区的副本，副本的作用就是提高Kafka的可靠性和可用性。同一个partition有多个replication的情况下，会通过zookeeper选出一个leader，其余的为follower，producer/consumer 读写partition的时候，就是通过leader进行的。当leader不可用时，会选择一个follower成为leader。在Kafka中，默认的最大副本数量是10个，而且副本的数量不能超过broker数量 consumer：消息消费者 consumer group：消息消费者组。为了提高Kafka的吞吐量。可以将多个consumer组成一个group，同一个partition数据只能被group中的一个consumer消费。同一个group里的consumer可以消费同一个topic的不同分区的数量。这样也可以保证，同一消息，不会被重复消费 二、Kafka核心规则 工作流程
producer先从集群中获取分区的leader producer将消息发送给leader leader将消息写入本地文件 follower从leader pull 消息 follower将消息写入本地文件后，向leader发送ACK leader收到所有副本的ACK后，向producer发送ACK 每条消息是追加到分区中，顺序写入磁盘，所以保证同一分区的数据是有序的 producer采用push模式将消息发布到broker follower是主动去leader pull消息进行同步的 producer如何确定数据该写到那个partition partition在写入的时候，可以指定需要写入的partition；如果指定，则写入对应的partition 如果没有指定partition，但是设置了key，则会根据key的值hash到一个partition 如果既没有partition，也没有key，则会轮询选出一个partition 如何保证消息不丢失：producer写入消息、follower同步leader消息的时候，都会返回ACK，通过ACK应答机制，可以确保消息不丢。在生产者向kafka写数据的时候，可以设定参数acks来确定kafka是否确认收到数据，这个值可以设置为0、1、all
0代表producer消息发往cluster不需要等到cluster返回ACK消息，所以设置这个值不能确保消息发送成功，安全性最低，但是效率最高 1代表producer消息发往cluster时，只要leader应答就可以发送下一条，所以这个设置只能确保发送给leader成功 all代表producer消息发往cluster时，需要所有的follower都完成从leader同步，才会发送下一条，确保leader发送成功并且所有follower都完成备份。安全性最高，但是效率最低 数据保存
partition结构：每个partition文件夹由多个segment文件组成，每组segment文件包含.index、.log文、.timeindex三个文件，其中.index、.log文件为索引文件，log文件就是存储message的地方。Kafka就是利用segment+index的方式解决查询效率低问题 message结构：message主要包含消息体、消息大小、offset、压缩类型等信息 存储策略：无论message是否被消费，Kafka都会保存所有消息，对于旧数据删除策略有两种：基于时间，默认7天；基于大小，默认1GB。 consumer group中consumer和partition的关系：
一个consumer可以消费多个partition中的数据 一个partition只能被一个consumer消费 三、Kafka吞吐量大的原因 四、QA leader的选举
kafka不是多数投票选举leader。kafka动态维护一组同步leader数据的副本（ISR in-sync-replication），只有这个组的成员才有资格当选leader，kafka副本写入不被认为是已提交，直到所有的同步副本已经接收才认为。这组ISR保存在zookeeper，正因为如此，在ISR中的任何副本都有资格当选leader，这是kafka的使用模型，有多个分区和确保leader平衡是很重要的一个重要因素。有了这个模型，ISR和f+1副本，kafka的主题可以容忍f失败而不会丢失已提交的消息。
成为ISR列表中的一员，需要满足两个条件：
副本节点必须能与zookeeper保持会话（心跳机制💗） 副本能够复制leader上的所有写操作，并且不能落后太多（卡住或滞后的副本由replica.lag.time.max.ms配置） 一旦follower从leader同步数据的延迟超过阀值，leader就会把它从ISR中剔除，放入OSR，新加入的follower也会加入OSR
AR(assigned replicas) = ISR+OSR (out of-sync-replicas)
如何保证已提交的信息不丢失
replication+leader选举机制</description></item><item><title>Cgroup_subsystem</title><link>https://caijin.dev/zh/linux/cgroup_subsystem/</link><pubDate>Thu, 22 Aug 2019 21:22:50 +0800</pubDate><author>caijin</author><guid>https://caijin.dev/zh/linux/cgroup_subsystem/</guid><description>上一篇cgroup主要讲了cgroup和常用的subsystem，算是理论部分，都说实践出真理，这篇文章就是实践部分了，介绍如何使用。
subsystem cpuset
限制 cpuset.cpus: 设置任务可以使用的CPU核心的编号，格式为：from_number-to_number, number，用,隔开 cpuset.mems: 设置cpu可使用的memory node，格式同上 统计 cpuset.effective_cpus: 在使用的cpu核心 cpuset.effective_mem: 在使用的memory node cpuset.memory_pressure：cupset中的分页 cpu
限制 cpu.cfs_quota_us: 设定周期内最多可使用的时间 cpu.cfs_period_us: 设置使用cpu的周期时间，需要和cfs_quota_us配合使用 统计 cpu.stat: 显示各种统计信息 cpuacct.stat: 统计用户态和内核态使用的cpu时长 cpuacct.usage_*: 统计每个任务使用的cpu时长 blkio
限制 blkio.throttle.read_bps_device: 设置读取设备的速率上限，格式为：device_num:node_number byte_per_second blkio.throttle.read_iops_device: 设置每秒读取设备的次数上限 blkio.throttle.write_bps_device: 设置写设备的速率上限 blkio.throttle.write_iops_device: 设置每秒写设备的次数 统计 blkio.reset_stats: 重置统计信息 blkio.throttle.io_service_bytes: 读设备/写设备的字节数 blkio.throttle.*_recursive: 各种统计数据的递归版本。这些文件显示与非递归对应文件相同的信息，但包括来自所有后代cgroup的统计信息 blkio.throttle.io_serviced: io次数 memory
限制
memory.limit_in_bytes: 设置内存使用限制，单位有k、m、g，-1时无限制
memory.max_usage_in_bytes: 设置最大内存使用量
memory.move_charge_at_immigrate: 设置移动的花费
memory.soft_limit_in_bytes: 软限制，需要比limit_in_bytes小
memory.oom_control：改参数填 0 或 1， 0表示开启，当 cgroup 中的进程使用资源超过界限时立即杀死进程，1表示不启用。默认情况下，包含 memory 子系统的 cgroup 都启用</description></item><item><title>Cgroup</title><link>https://caijin.dev/zh/linux/cgroup/</link><pubDate>Mon, 19 Aug 2019 20:18:42 +0800</pubDate><author>caijin</author><guid>https://caijin.dev/zh/linux/cgroup/</guid><description>简介 Croups(control groups)是Linux内核提供的一种可以限制、记录、隔离进程(进程组)所使用的的物理资源（如：CPU、memory、IO、device等）的机制。是轻量级虚拟化技术（docker、lxc）的基础之一。另外的基础包括namespace、ufs(union file system)等。
概念 基本概念 任务（task）。在cgroup中，任务就是系统的一个进程。 控制组（control group）。控制组就是一组按照某种标准划分的进程，比如按内存大小，cpu的使用率，或者io的速率限制划分成组。一个进程可以加入到某个控制组，也可以从一个组迁移到另外一个组。一个组中的进程可以使用cgroup以控制组为单位分配的资源，同时受到组分配到的资源的限制。 层级（hierarchy）。控制组可以组织成为层级的形式，组成一棵控制组树。控制组树上的子节点是父节点控制组的孩子，继承父控制组的资源限制。 子系统（subsystem）。一个子系统就是一个资源控制器，子系统必须附加（attach）到一个层级上才能使用。 关系和限制 一个子系统最多只能附加到一个层级。 一个层级可以有多个子系统。 一个任务可以是多个cgroup的成员，但是这些cgroup必须是不同的层级。 任务创建子任务时，子任务自动成为其父任务所在的cgroup成员。可以把子任务移动到不同的cgroup中，但最开始时，它总是继承父任务的cgroup。 系统支持的子系统 查看系统支持的cgroup
# 1、安装cgroup工具，如果已经安装，请忽略 sudo apt install cgroup-tools # 2、查看系统的子系统 $lssubsys cpuset cpu,cpuacct blkio memory devices freezer net_cls,net_prio perf_event hugetlb pids rdma jin@k53:~$ jin@k53:~$ uname -a Linux k53 5.0.0-25-generic #26-Ubuntu SMP Thu Aug 1 12:04:58 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux jin@k53:~$ lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 19.</description></item><item><title>Namespace_Improve</title><link>https://caijin.dev/zh/linux/namespace_improve/</link><pubDate>Fri, 16 Aug 2019 21:03:23 +0800</pubDate><author>caijin</author><guid>https://caijin.dev/zh/linux/namespace_improve/</guid><description>在上一篇namespace的文章中，我们了解并通过程序写了一个简单版的容器，体验了Linux namespace的功能，但是还有两个美中不足的地方，一个是需要使用root权限才能够运行我们的程序，另外一个我们在容器中使用ps看到pid为1的进程是/proc/self/exe child sh，而不是sh。所以这篇文章就讲讲如何解决这两个问题。
root权限 在Linux namespace中，只有user namespace 是可以被普通用户创建的，其他的namespace 都需要有root权限才可以。但这样就会有问题：
1、并不是每个用户都有sudo权限；
2、进程的安全性。
其实第一点还好解决，关键是第二点，运行的进程是以root权限运行的，这就有可能导致安全问题，比如，容器内的进程受到攻击，控制权到了攻击者的手中，此时的进程是用root权限运行的，所以攻击者可以用该进程执行任意权限的操作。
也有人可能会想，我们不是已经把所有的namespace都clone出来了么，rootfs也改变了，即使被攻击了，影响的范围也就是container中。说的是没错，不过，如果我们把主机的目录当作卷挂载到了container中，那么攻击者所能影响的范围就扩大到了主机中。所以，我们就把这个影响减少到最少&amp;mdash;当前用户的权限。看看代码：
uid := os.Getuid() gid := os.Getgid() cmd.SysProcAttr = &amp;amp;syscall.SysProcAttr{ Cloneflags: syscall.CLONE_NEWUSER | syscall.CLONE_NEWUTS | syscall.CLONE_NEWNS | syscall.CLONE_NEWIPC | syscall.CLONE_NEWNET | syscall.CLONE_NEWPID, UidMappings: []syscall.SysProcIDMap{{0, uid, 1}}, GidMappings: []syscall.SysProcIDMap{{0, gid, 1}}, Credential: &amp;amp;syscall.Credential{ Uid: 0, Gid: 0, }, }第一行和第二行得到当前登陆用户的uid/gid (user id/ group id)；
第六行，我们做了一个uid的映射，syscall.SysProcIDMap第一个参数是容器内的用户的id，0是root，第二个参数是需要映射的用户的权限，第三个参数是映射范围，一般用1就可以，表示一一对应；第七行也是一样，只不过是gid的映射；
第8行，设置容器内用户的uid和gid，都为0，说明是用户是root，用户所在的组是root组
重新编译运行：
jin@k53:~/go-test$ go build namespace.go jin@k53:~/go-test$ ./namespace run sh p pid: 4342 c p pid: 0 c pid: 1 / # / # 可以看到现在不用root权限就可以运行了。docker 也不需要root权限就能运行呢，向docker又前进了一小步，而且，容器内是root，容器外，sh其实是以普通用户执行的，安全性又得到了保证。其实这种安全性是很粗糙的，关于容器的安全性，是一个比较有意思的话题，后面也许会单独谈谈。</description></item><item><title>Namespace</title><link>https://caijin.dev/zh/linux/namespace/</link><pubDate>Wed, 14 Aug 2019 19:33:19 +0800</pubDate><author>caijin</author><guid>https://caijin.dev/zh/linux/namespace/</guid><description><![CDATA[简介 linux namespace 是linux内核提供的一种环境（资源）隔离的方式，主要提供了UTS、IPC、network、User、mount、PID的隔离
类别 系统调用参数 内核版本 作用 UTS CLONE_NEWUTS Linux 2.6.19 隔离主机名称，域名称 IPC CLONE_NEWIPC Linux 2.6.10 隔离进程间通信 Network CLONE_NEWNET Linux 2.6.29 隔离网络 User CLONE_NEWUSER Linux 3.8 隔离用户 Mount CLONE_NEWNS Linux 2.4.19 隔离挂载点 PID CLONE_NEWPID linux 2.6.24 隔离进程ID UTC 未隔离之前，我们先看看主机名，打开两个终端，终端1执行hostname，查看当前主机名，第二个终端中执行sudo hostname xxx再在终端1中执行hostname，可以发现主机名称已经被修改了。
为了能够更好的感受下namespace，自己动手写个程序是最好不过的方式了，下面是我写的一个demo，文件名是namespace.go
package main import ( &#34;fmt&#34; &#34;os&#34; &#34;os/exec&#34; &#34;syscall&#34; ) func main() { cmd := exec.Command(os.Args[1]) cmd.SysProcAttr = &amp;syscall.SysProcAttr{ Cloneflags: syscall.CLONE_NEWUTS, } cmd.Stdin = os.Stdin cmd.Stdout = os.Stdout cmd.]]></description></item><item><title>Arch_install</title><link>https://caijin.dev/zh/linux/arch_install/</link><pubDate>Sat, 13 Jul 2019 22:24:48 +0800</pubDate><author>caijin</author><guid>https://caijin.dev/zh/linux/arch_install/</guid><description>使用*nux 制作U盘启动盘 fdisk -l #查看当前系统中的磁盘设备，这里u盘设备是/dev/disk2 umount /dev/disk2 #卸载挂载点，备份u盘里面的重要文件，制作启动盘会执行格式化 sudo dd if=archlinux-2019.07.01-x86_64.iso of=/dev/disk2 bs=1m #这用时可能会比较久，稍等一下准备 制作好u盘启动盘之后，设置电脑从u盘启动，之后进入到arch live里默认以root用户登录，之后就可以进行准备操作了。
vim /etc/hostname #修改安装后的主机名 fdisk /dev/sda #分区，注意设备，我这里是sda mkfs.ext4 /dev/sda1 #格式化分区 mount /dev/sda1 /mnt #挂载分区 vim /etc/pacman.d/mirrorlist #将中国区的源放到非注释的第一行，会提高软件包的下载速度，越靠前，优先级越高。 pacman -Syy #更新镜像源 dhcpcd #使用dhcp自动获取ip地址 ip addr show #应该能够看到分配到ip地址了，如果使用的wifi，并且加密方式是wpa，则执行以下命令，连接wifi wpa_supplicant -i wpl3s0 -c &amp;lt;(wpa_passphrase wifi-ssid password) #wpl3s0 wifi-ssid password 分别是无线网卡名称，wifi名称，wifi密码安装 pacstrap /mnt base base-devel #开始安装到mnt，一路回车就好，稍等直到完成。 arch-chroot /mnt #改变root目录 vim /etc/locale.gen #删除en_US.UTF-8 和 zh_CN.UTF-8 前面的注释 locale-gen #生成语言区域的一些文件 ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime #设置时区为亚洲上海的时区(+08:00)安装引导程序GRUB pacmanm -S os-prober grub #安装grub及依赖 grub-install --target=i386-pc /dev/sda #BIOS方式 grub-install /dev/sda #EFI方式 grub-mkconfig -o /boot/grub/grub.</description></item></channel></rss>
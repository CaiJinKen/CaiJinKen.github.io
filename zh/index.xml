<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>*&lt;^_^>*</title><link>https://caijin.dev/zh/</link><description>*&lt;^_^>*</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>xxxx</copyright><lastBuildDate>Sat, 02 May 2020 20:20:42 +0800</lastBuildDate><atom:link href="https://caijin.dev/zh/index.xml" rel="self" type="application/rss+xml"/><item><title>Docker + Gitlab + Jenkins 搭建持续集成环境</title><link>https://caijin.dev/zh/docker-+-gitlab-+-jenkins-%E6%90%AD%E5%BB%BA%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E7%8E%AF%E5%A2%83/</link><pubDate>Sat, 02 May 2020 20:20:42 +0800</pubDate><author>caijin</author><guid>https://caijin.dev/zh/docker-+-gitlab-+-jenkins-%E6%90%AD%E5%BB%BA%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E7%8E%AF%E5%A2%83/</guid><description><![CDATA[Docker + Gitlab + Jenkins 搭建持续集成环境 安装docker sudo apt update sudo apt install apt-transport-https \ ca-certificates \ curl \ gnupg-agent \ software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository \ &#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu \ $(lsb_release -cs) \ stable&#34; sudo apt update sudo apt install docker-ce docker-ce-cli containerd.io安装Gitlab sudo docker pull gitlab/gitlab-ce:nightly由于众所周知的原因，国内拉取某些镜像慢的一批，所以我们需要把docker镜像源换一下，
sudo vim /etc/docker/daemon.json我这里替换为网易和百度的源，当然也可以换成任意你想要的一个或多个
{ &#34;registry-mirrors&#34;: [ &#34;https://hub-mirror.c.163.com&#34;, &#34;https://mirror.baidubce.com&#34; ] }之后，重启docker
sudo systemctl daemon-reload sudo systemctl restart docker镜像拉取好了以后，启动容器]]></description></item><item><title>redis必知必会</title><link>https://caijin.dev/zh/redis/redis-%E5%85%B6%E4%BB%96/</link><pubDate>Sat, 02 May 2020 20:20:42 +0800</pubDate><author>caijin</author><guid>https://caijin.dev/zh/redis/redis-%E5%85%B6%E4%BB%96/</guid><description>Redis 其他 redis 数据淘汰机制 当机器内存不够的时候（达到物理机器或者配置的内存上限时），redis会依据数据淘汰机制淘汰一部分数据，有以下6种方式：
volatile-lru： 在设置了过期时间的key中，使用LRU（最近最少使用）算法，将最近最少使用的key淘汰 volatile-ttl： 在设置了过期时间的key中，根据TTL（time to live）时间，将快要过期的数据淘汰 volatile-random： 在设置了过期时间的key中，随机淘汰数据 allkeys-lru： 在所有key中，淘汰最近最少使用的数据 allkeys-random： 在所有key中，随机淘汰数据 noeviction： 禁止淘汰数据 redis缓存穿透、击穿、雪崩 缓存穿透：请求数据在redis中查询，查询不到，最后请求落到了数据库 缓存击穿：热门数据突然失效，大量请求到了数据库 缓存雪崩：大量数据同时失效 Note: 解决方案：
穿透：对于非法参数（eg：id&amp;lt;=0）增加参数校验，过滤掉不存在数据的请求；对于合法参数(eg: id=xxxx)，但是数据不存在：将数据设置为null 击穿：设置热点数据永不过期 雪崩：避免大量数据同一时间过期：分散过期时间；分散数据到不同缓存数据库 master-slave 作用：主从备份，防止节点宕机；读写分离，达到负载均衡目的，提高系统吞吐量 全量同步，发生在slave初始化阶段： slave连接master，发送SYNC命令 master收到命令后，开始执行BGSAVE命令生成rdb文件，并使用缓冲区记录此后所执行的_写命令_ master执行完BGSAVE命令后，向所有slave发送rdb文件 slave收到rdb文件后，丢弃所有旧数据，载入收到的数据 master发送完文件后，就开始放送缓冲区中的写命令 slave完成数据载入后，开始接收命令请求，并执行来自master同步的写命令 增量同步：slave初始化后正常工作，接收master发送的写命令。master每执行一个写命令就会向slave发送相同的写命令，slave接收并执行收到的写命令 同步策略：master、slave刚刚连接的时候，进行全量同步；全量同步结束后开始增量同步。如果有需要的话，slave在任何时候都可以发起全量同步。redis策略为，首先先进行增量同步，如不成功，进行全量同步 </description></item><item><title>redis持久化</title><link>https://caijin.dev/zh/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/</link><pubDate>Sat, 02 May 2020 20:20:42 +0800</pubDate><author>caijin</author><guid>https://caijin.dev/zh/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96/</guid><description>redis持久化 两种方式：RDB、AOF
RDB，redis-database，使用压缩的二进制文件保存的是redis内存中完整的数据，相当于数据的快照，默认的持久化方式，可以手动执行以下命令执行，可以在配置文件中自动执行
SAVE命令：会阻塞服务器进程，此时所有命令都会一直阻塞直到save命令执行完毕 BGSAVE命令：会重新起一个进程处理，不会阻塞任何命令 恢复过程：
如果没开启AOF持久化，服务器才会使用RDB文件还原数据 如果开启了AOF持久化，服务器会优先使用AOF文件还原数据 AOF，append-only-file，默认关闭，服务器在执行完写命令后，会以协议格式将命令追加到AOF缓冲区，然后服务器根据appendfsync选项决定何时将AOF缓冲区内容写入到AOF文件。
appendfsync：
always，每个写命令都会同步到AOF文件，是最安全的方式，即使故障停机，丢失数据最多就一个写命令的数据 everysec，每秒钟都会同步数据到AOF文件，故障停机最多就丢失一秒钟的写入命令的数据，是AOF方式的默认值 no，从不同步数据，出现故障后，会丢失上次同步之后的所有写入数据 恢复过程：
创建一个伪客户端 从AOF文件分析并读取一条写命令 伪客户端执行命令 重复上两个步骤，直到AOF文件所有写命令执行完毕 随着运行时间的增加，AOF文件会越来越大，占用的磁盘空间会增加，而且数据恢复的过程所耗费的时间也会增加，为了解决这一问题，redis提供了AOF重写功能：redis会创建一个新的AOF文件替代现有AOF文件，新旧两个文件保存的数据相同，只不过新AOF文件保存的是精简后的命令，不会浪费存储空间
AOF重写过程：
服务器创建子进程，子进程开始AOF文件重写 服务器执行所有命令外还要将写命令写入AOF缓冲区和AOF重写缓冲区 子进程完成AOF重写后向父进程发送信号，父进程收到信号后： 将AOF重写缓冲区内容写入到新AOF文件中，保证新AOF文件保存的数据和服务器当前的数据一致 对新AOF文件重命名，覆盖现有AOF文件，完成新旧AOF文件替换 两种持久化方式的区别 实现方式
RDB持久化记录的是结果，AOF持久化记录的是过程
文件体积
记录结果的方式肯定比记录过程的方式占用的存储空间小，即：RDB文件占用的存储空间小
安全性
AOF的安全性要比RDB的高。RDB持久化会丢失从上次保存以后的数据，而AOF持久化最多丢失1s的数据
优先级
AOF的优先级比RDB的高</description></item><item><title>unsafe.Pointer</title><link>https://caijin.dev/zh/golang/unsafe.pointer/</link><pubDate>Sat, 02 May 2020 20:20:42 +0800</pubDate><author>caijin</author><guid>https://caijin.dev/zh/golang/unsafe.pointer/</guid><description><![CDATA[unsafe.Pointer相当于指向任意类型的指针(*指针)，但它有四种特殊的操作不同于一般的指针：
任意类型的指针(*)可以转换为Pointer Pointer指针也可以转换为任意类型的指针 uintptr可以转换成Pointer Pointer可以也可以转换为uintptr 即:
Pointer &lt;&mdash;&gt;(*)
uintptr&lt;&mdash;-&gt; Pointer
Pointer允许程序忽略类型检测从而读写任意的内存，所以在使用unsafe包的时候要格外小心。
比如将float64转化为int64，正常情况下是需要遵守go的类型检测，进行类型强转之后才能正常运行：
var ( sourceValue float64 targetValue int46 ) sourceValue = 300.00 targetValue = int64(sourceValue) // targetValue = sourceValue //err: type not match 使用示例：
将*T1转换为*T2
func Float64bits(f float64) uint64{ return (*uint64)(unsafe.Pointer(&amp;f)) } //unsafe.Pointer(&amp;f)即第一条规则：将任意类型指针转换为Pointer //(*uint64)(unsafe.Pointer)即第二条规则：将Pointer转换为任意类型 将Pointer转换为uintptr(取地址值)
func Pointer2uintptr(p unsafe.Pointer) uintprt{ return (uintptr)(p) } //(uintprt)(unsafe.Pointer)即第三条规则：将Pointer转换为uintptr Note:一般情况下不要这么用，因为uintptr本质上是整数类型，当Pointer中的指针值变了以后，uintptr的值并不随着原始指针的值变化，这里仅仅只是出于演示的目的这么写，所以别用任何变量保存Pointer转换为uintptr之后的值
将指针和偏移做运算以后返回
p = unsafe.Pointer(uintptr(p)+offset) //offset 是一个整型的值，可以是计算后的，比如 //对于结构体： f = unsafe.Pointer(uintptr(unsafe.Pointer(&amp;s))+unsafe.Offsetof(s.f)) //上面等同于 f = unsafe.Pointer(&amp;s.f) //对于slice e := unsafe.]]></description></item><item><title>golang内存对齐</title><link>https://caijin.dev/zh/golang/%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90/</link><pubDate>Sat, 02 May 2020 20:18:42 +0800</pubDate><author>caijin</author><guid>https://caijin.dev/zh/golang/%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90/</guid><description>golang内存对齐 一个golang的结构体，在内存中是如何存放的呢？即，结构体的内存结构是什么样的呢？有没有优化的空间呢？今天来一探究竟
note:我所用的是64bite的机器，在32位的机器有些类型的大小是不一样的，比如int
基本数据类型的大小
var ( boolField bool byteField byte int8Field int8 int16Field int16 int32Field int32 intField int int64Field int64 float32Field float32 float64Field float64 stringField string mapField map[string]interface{} sliceField []interface{} ) fmt.Println(unsafe.Sizeof(boolField)) //1 fmt.Println(unsafe.Sizeof(byteField)) //1 fmt.Println(unsafe.Sizeof(int8Field)) //1 fmt.Println(unsafe.Sizeof(int16Field)) //2 fmt.Println(unsafe.Sizeof(int32Field)) //4 fmt.Println(unsafe.Sizeof(intField)) //8 fmt.Println(unsafe.Sizeof(int64Field)) //8 fmt.Println(unsafe.Sizeof(float32Field)) //4 fmt.Println(unsafe.Sizeof(float64Field)) //8 fmt.Println(unsafe.Sizeof(stringField)) //16 fmt.Println(unsafe.Sizeof(mapField)) //8 fmt.Println(unsafe.Sizeof(sliceField)) //24 note: unsafe.Sizeof()返回的是字节数，如果有这么一个结构体，它所占用的内存是28B么？
type testStruct struct { boolField bool stringField string byteField byte int64Field int64 int16Field int16 }运行一下看看：</description></item><item><title>kafka简介</title><link>https://caijin.dev/zh/kafka/kafka/</link><pubDate>Sat, 02 May 2020 20:18:42 +0800</pubDate><author>caijin</author><guid>https://caijin.dev/zh/kafka/kafka/</guid><description>Kafka 一、基本概念 kafka cluster：kafka集群，一个集群由多个实例（broker）组成，通过zookeeper进行元数据（brokerID、broker 地址等信息，partition的leader、follower信息等）共享与同步 broker：kafka集群中的一个kafka服务实例，集群内每个broker都有一个不重复的编号，如broker-0、broker-1 producer：消息生产者 topic：消息主题，可以理解为消息分类，为逻辑概念。Kafka的消息就保存在topic，每个broker上都可以创建多个topic。 partition：topic的分区，每个topic可以有多个分区，分区的作用是做负载，提高Kafka的吞吐量。同一个topic在不同分区的数据是不重复的，partition的表现形式就是一个个文件夹，为物理概念。 replication：分区的副本，副本的作用就是提高Kafka的可靠性和可用性。同一个partition有多个replication的情况下，会通过zookeeper选出一个leader，其余的为follower，producer/consumer 读写partition的时候，就是通过leader进行的。当leader不可用时，会选择一个follower成为leader。在Kafka中，默认的最大副本数量是10个，而且副本的数量不能超过broker数量 consumer：消息消费者 consumer group：消息消费者组。为了提高Kafka的吞吐量。可以将多个consumer组成一个group，同一个partition数据只能被group中的一个consumer消费。同一个group里的consumer可以消费同一个topic的不同分区的数量。这样也可以保证，同一消息，不会被重复消费 二、Kafka核心规则 工作流程
producer先从集群中获取分区的leader producer将消息发送给leader leader将消息写入本地文件 follower从leader pull 消息 follower将消息写入本地文件后，向leader发送ACK leader收到所有副本的ACK后，向producer发送ACK 每条消息是追加到分区中，顺序写入磁盘，所以保证同一分区的数据是有序的 producer采用push模式将消息发布到broker follower是主动去leader pull消息进行同步的 producer如何确定数据该写到那个partition partition在写入的时候，可以指定需要写入的partition；如果指定，则写入对应的partition 如果没有指定partition，但是设置了key，则会根据key的值hash到一个partition 如果既没有partition，也没有key，则会轮询选出一个partition 如何保证消息不丢失：producer写入消息、follower同步leader消息的时候，都会返回ACK，通过ACK应答机制，可以确保消息不丢。在生产者向kafka写数据的时候，可以设定参数acks来确定kafka是否确认收到数据，这个值可以设置为0、1、all
0代表producer消息发往cluster不需要等到cluster返回ACK消息，所以设置这个值不能确保消息发送成功，安全性最低，但是效率最高 1代表producer消息发往cluster时，只要leader应答就可以发送下一条，所以这个设置只能确保发送给leader成功 all代表producer消息发往cluster时，需要所有的follower都完成从leader同步，才会发送下一条，确保leader发送成功并且所有follower都完成备份。安全性最高，但是效率最低 数据保存
partition结构：每个partition文件夹由多个segment文件组成，每组segment文件包含.index、.log文、.timeindex三个文件，其中.index、.log文件为索引文件，log文件就是存储message的地方。Kafka就是利用segment+index的方式解决查询效率低问题 message结构：message主要包含消息体、消息大小、offset、压缩类型等信息 存储策略：无论message是否被消费，Kafka都会保存所有消息，对于旧数据删除策略有两种：基于时间，默认7天；基于大小，默认1GB。 consumer group中consumer和partition的关系：
一个consumer可以消费多个partition中的数据 一个partition只能被一个consumer消费 三、Kafka吞吐量大的原因 四、QA leader的选举
kafka不是多数投票选举leader。kafka动态维护一组同步leader数据的副本（ISR in-sync-replication），只有这个组的成员才有资格当选leader，kafka副本写入不被认为是已提交，直到所有的同步副本已经接收才认为。这组ISR保存在zookeeper，正因为如此，在ISR中的任何副本都有资格当选leader，这是kafka的使用模型，有多个分区和确保leader平衡是很重要的一个重要因素。有了这个模型，ISR和f+1副本，kafka的主题可以容忍f失败而不会丢失已提交的消息。
成为ISR列表中的一员，需要满足两个条件：
副本节点必须能与zookeeper保持会话（心跳机制💗） 副本能够复制leader上的所有写操作，并且不能落后太多（卡住或滞后的副本由replica.lag.time.max.ms配置） 一旦follower从leader同步数据的延迟超过阀值，leader就会把它从ISR中剔除，放入OSR，新加入的follower也会加入OSR
AR(assigned replicas) = ISR+OSR (out of-sync-replicas)
如何保证已提交的信息不丢失
replication+leader选举机制</description></item><item><title>mysql简介</title><link>https://caijin.dev/zh/mysql/mysql/</link><pubDate>Sat, 02 May 2020 20:18:42 +0800</pubDate><author>caijin</author><guid>https://caijin.dev/zh/mysql/mysql/</guid><description>Mysql MyISAM vs Innodb?
mysql的索引有哪些
聚簇索引
在innodb表上定义了一个主键，innodb默认会使用它作为组簇索引（建议每个表都定义个主键） 如果没有定义主键，innodb会查找第一个【唯一索引】作为聚簇索引 如果既没有定义主键，又没有唯一索引，innodb会在内部生成一个名为_GEN_CLUST_INDEX_ 的隐式聚簇索引 聚簇索引如何加快查询速度：因为索引搜索直接指向包含所有行数据页（data page）
非聚簇索引
非聚簇索引通常也被称为二级索引或辅助索引，在innodb中，每个辅助索引中的每条记录都会包含该行的主键列 ( 也就是聚簇索引的键 ) ，以及为辅助索引指定的列。InnoDB 使用此主键值来搜索聚簇索引中的行
以上两者的区别
划分依据
InnoDB 会使用聚簇索引来保存数据，而非聚簇索引的目的仅仅是加快查询速度
主要区别
聚簇索引是唯一的，一个 InnoDB 表只有一个聚簇索引，而且一定会有一个聚簇索引，如果不存在，Innodb 存储引擎会自动添加一个 非聚簇所以可以有多个，而且只能由用户自己添加，InnoDB 默认并不会创建任何非聚簇索引 包含关系
非聚簇索引中一定包含了聚簇索引的列值，但反过来却不存在
什么是组合索引，匹配原则是什么
什么是多表连接？有哪些连接类型，原理是什么？
事物的隔离级别以及特征
级别 说明 Read uncommitted 当一个事物A更改了数据，但还未提交的时候，另外一个事物B读取这个数据的时候，读取的是A未提交的数据。如果A回滚了事物，就发生了脏读 Read committed 事物A读取了数据，事物B紧接着更新并提交了数据，当事物A再次读取该数据时，数据已经发生了改变，同一个事物，多次读取的数据不一致，就是所谓不可重复读 Repeatable read 当一个事物开始的时候，其他的事物就不能对数据进行更改，这样，数据就是可重复读的了。但是这样还是不能避免幻读：事物A开启了以后一直读取的是备份数据，事物B在这个时候删除了数据并提交了，但是A事物查询到的还是旧数据，这样就产生幻读了 Serializable 这是最高的事物隔离级别，事物只能一个个顺序执行，所以性能很低 Innodb是如何实现行锁的？
mysql锁类型
全局锁：对整个数据库实例加锁，主要用于全库备份 表级锁：表锁和元数据锁MDL，表锁：如果不能确定唯一性的话，会对整个表进行加锁；如果没有更改表结构，MDL加读锁，否则加写锁，读锁和写锁是互斥的 行锁：针对特定的数据加锁，mysql对索引加锁，oracle是对数据加锁，innodb行锁的算法： Record locks：为索引纪录上锁，如果没有定义索引，Innodb会为该表创建一个隐藏的聚簇索引，并使用该索引 Gap locks：该锁会锁定一个范围，但是不包括纪录本身。 Next-key locks：就是record locks和gap locks的组合，即锁定一个范围和该纪录本身。Innodb使用该锁解决幻读问题。如果索引具有唯一性，则innodb会将next-key locks自动降为record locks mysql组合索引按照最左匹配的原则进行匹配
比如有个key（a,b,c)，则支持a|a,b|a,b,c 3种组合进行查找，但不支持b，c查找，而且与where条件的顺序无关，因为优化器会对sql进行优化
索引失效的条件：
在索引上做任何操作（计算，函数，自动或者手动类型转换），会导致索引失效而转向全表扫描 存储索引不能使用索引_范围条件_ 右边的列 使用不等于（！= ｜｜ &amp;lt;&amp;gt;）的时候无法使用索引，会导致全表扫描 like以通配符开头，索引失败，全表扫描 一般建议：</description></item><item><title>axios的使用</title><link>https://caijin.dev/zh/front-end/axios%E7%9A%84%E4%BD%BF%E7%94%A8/</link><pubDate>Sat, 18 Apr 2020 21:24:19 +0800</pubDate><author>caijin</author><guid>https://caijin.dev/zh/front-end/axios%E7%9A%84%E4%BD%BF%E7%94%A8/</guid><description><![CDATA[axios 的使用 axios 是前端最常见的网络库。主要调用方式有两种形式：axios(config) 和 axios(url, config)，下面简要介绍axios的使用。
1、请求方法 常用的http请求方法有以下5个
方法 作用 GET 请求资源 POST 新增资源 PUT 更新资源（需要资源的所有信息） PATCH 更新资源的部分信息 DELETE 删除资源 例如有user对象：{&quot;id&quot;:1, &quot;name&quot;:&quot;axios-user&quot;, &quot;age&quot;:20}
使用axios发起请求可以用axios(config)的形式，如下所示：
axios({ method:&#34;get&#34;,//请求方法 url:&#34;/users&#34;,//请求的URL params:{id:1},//get、delete方法的请求参数，会放到url之后 data:{}//post、put、patch方法的请求参数，会放到body中 }).then((resp)=&gt;{ //请求成功的处理 console.log(resp.data)//控制台打印返回的body数据 }).catch((err)=&gt;{ //请求失败的处理 console.log(err) }).then(()={ //不管成功与否，都会执行 console.log(&#34;此处一定会执行&#34;) })对于其他的方式，换一下config对象种的method即可
2、别名 如果有很多的请求，每个我们都需要写一堆像上面1中的axios的配置信息，一个是写起来比较麻烦，另外一个，代码看起来也比较乱，axios也提供了对应请求方法的别名函数，用axios(url, config)的形式，如下所示：
//get axios(&#34;/users&#34;,{params:{id:1}}).then((resp)=&gt;{}) //等同于如下方式 axios.get(&#34;/users&#34;,{params:{id:1}}).then((resp)=&gt;{}) //post axios.post(&#34;/user&#34;,{id:2,name:&#34;axios-user2&#34;,age:22}) //put 只更新部分信息也需要将整个资源对象提交 axios.put(&#34;/user&#34;,{id:2,name:&#34;axios-xxx&#34;,age:22}) //patch 只需提交唯一标识和更改的数据项即可 axios.patch(&#34;/users&#34;,{id:2,age:18}) //delete axios.delete(&#34;/users&#34;,{params:{id:2}})3、并发请求 axios 也支持同时发起多个请求，并且可以获取到每个请求的结果，使用axios.all() 和 axios.spread()即可，all()方法的参数是函数数组，spread()方法接受的是回调函数，函数中的参数即是all()中的请求结果，顺序和all()保持一致。
例子如下：
axios.all( [ axios.get(&#34;/users&#34;),//请求1 axios.get(&#34;/students&#34;),//请求2 axios.post(&#34;/teachers&#34;,{id:5,name:&#34;teacher wang&#34;,age:35})//请求3 ] ).then( axios.]]></description></item><item><title>Cgroup_subsystem</title><link>https://caijin.dev/zh/linux/cgroup_subsystem/</link><pubDate>Thu, 22 Aug 2019 21:22:50 +0800</pubDate><author>caijin</author><guid>https://caijin.dev/zh/linux/cgroup_subsystem/</guid><description>上一篇cgroup主要讲了cgroup和常用的subsystem，算是理论部分，都说实践出真理，这篇文章就是实践部分了，介绍如何使用。
subsystem cpuset
限制 cpuset.cpus: 设置任务可以使用的CPU核心的编号，格式为：from_number-to_number, number，用,隔开 cpuset.mems: 设置cpu可使用的memory node，格式同上 统计 cpuset.effective_cpus: 在使用的cpu核心 cpuset.effective_mem: 在使用的memory node cpuset.memory_pressure：cupset中的分页 cpu
限制 cpu.cfs_quota_us: 设定周期内最多可使用的时间 cpu.cfs_period_us: 设置使用cpu的周期时间，需要和cfs_quota_us配合使用 统计 cpu.stat: 显示各种统计信息 cpuacct.stat: 统计用户态和内核态使用的cpu时长 cpuacct.usage_*: 统计每个任务使用的cpu时长 blkio
限制 blkio.throttle.read_bps_device: 设置读取设备的速率上限，格式为：device_num:node_number byte_per_second blkio.throttle.read_iops_device: 设置每秒读取设备的次数上限 blkio.throttle.write_bps_device: 设置写设备的速率上限 blkio.throttle.write_iops_device: 设置每秒写设备的次数 统计 blkio.reset_stats: 重置统计信息 blkio.throttle.io_service_bytes: 读设备/写设备的字节数 blkio.throttle.*_recursive: 各种统计数据的递归版本。这些文件显示与非递归对应文件相同的信息，但包括来自所有后代cgroup的统计信息 blkio.throttle.io_serviced: io次数 memory
限制
memory.limit_in_bytes: 设置内存使用限制，单位有k、m、g，-1时无限制
memory.max_usage_in_bytes: 设置最大内存使用量
memory.move_charge_at_immigrate: 设置移动的花费
memory.soft_limit_in_bytes: 软限制，需要比limit_in_bytes小
memory.oom_control：改参数填 0 或 1， 0表示开启，当 cgroup 中的进程使用资源超过界限时立即杀死进程，1表示不启用。默认情况下，包含 memory 子系统的 cgroup 都启用</description></item><item><title>Cgroup</title><link>https://caijin.dev/zh/linux/cgroup/</link><pubDate>Mon, 19 Aug 2019 20:18:42 +0800</pubDate><author>caijin</author><guid>https://caijin.dev/zh/linux/cgroup/</guid><description>简介 Croups(control groups)是Linux内核提供的一种可以限制、记录、隔离进程(进程组)所使用的的物理资源（如：CPU、memory、IO、device等）的机制。是轻量级虚拟化技术（docker、lxc）的基础之一。另外的基础包括namespace、ufs(union file system)等。
概念 基本概念 任务（task）。在cgroup中，任务就是系统的一个进程。 控制组（control group）。控制组就是一组按照某种标准划分的进程，比如按内存大小，cpu的使用率，或者io的速率限制划分成组。一个进程可以加入到某个控制组，也可以从一个组迁移到另外一个组。一个组中的进程可以使用cgroup以控制组为单位分配的资源，同时受到组分配到的资源的限制。 层级（hierarchy）。控制组可以组织成为层级的形式，组成一棵控制组树。控制组树上的子节点是父节点控制组的孩子，继承父控制组的资源限制。 子系统（subsystem）。一个子系统就是一个资源控制器，子系统必须附加（attach）到一个层级上才能使用。 关系和限制 一个子系统最多只能附加到一个层级。 一个层级可以有多个子系统。 一个任务可以是多个cgroup的成员，但是这些cgroup必须是不同的层级。 任务创建子任务时，子任务自动成为其父任务所在的cgroup成员。可以把子任务移动到不同的cgroup中，但最开始时，它总是继承父任务的cgroup。 系统支持的子系统 查看系统支持的cgroup
# 1、安装cgroup工具，如果已经安装，请忽略 sudo apt install cgroup-tools # 2、查看系统的子系统 $lssubsys cpuset cpu,cpuacct blkio memory devices freezer net_cls,net_prio perf_event hugetlb pids rdma jin@k53:~$ jin@k53:~$ uname -a Linux k53 5.0.0-25-generic #26-Ubuntu SMP Thu Aug 1 12:04:58 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux jin@k53:~$ lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 19.</description></item></channel></rss>